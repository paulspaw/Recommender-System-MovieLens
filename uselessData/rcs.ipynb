{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 电影推荐系统"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据概览\n",
    "\n",
    "本推荐系统使用的是MovieLens 100K 数据集。\n",
    "\n",
    "数据集分为6个文件：电影评分 u.data,电影类别 u.genre,数据集概要 u.info,电影信息 u.info,职业列表 u.occupation,用户信息 u.user。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 电影评分\n",
    "文件里包含：用户id，电影id，评分（1-5），时间戳。\n",
    "\n",
    "数据中的格式：UserID MovieID Rating。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>TimeStamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  TimeStamp\n",
       "0     196      242       3  881250949\n",
       "1     186      302       3  891717742\n",
       "2      22      377       1  878887116\n",
       "3     244       51       2  880606923\n",
       "4     166      346       1  886397596"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv(\"./ml-100k/u.data\", \n",
    "                      header=None, \n",
    "                      sep='\\s', \n",
    "                      names=['UserID', 'MovieID', 'Rating','TimeStamp'], \n",
    "                      engine='python')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 电影类别\n",
    "文件里包含：genre，genreID。\n",
    "\n",
    "数据中的格式：genre | genreID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>GenreID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Action</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adventure</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animation</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Children's</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Comedy</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Crime</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Documentary</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Drama</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fantasy</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Film-Noir</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Horror</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Musical</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mystery</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Romance</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sci-Fi</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Thriller</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>War</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Western</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Genre  GenreID\n",
       "0       unknown        0\n",
       "1        Action        1\n",
       "2     Adventure        2\n",
       "3     Animation        3\n",
       "4    Children's        4\n",
       "5        Comedy        5\n",
       "6         Crime        6\n",
       "7   Documentary        7\n",
       "8         Drama        8\n",
       "9       Fantasy        9\n",
       "10    Film-Noir       10\n",
       "11       Horror       11\n",
       "12      Musical       12\n",
       "13      Mystery       13\n",
       "14      Romance       14\n",
       "15       Sci-Fi       15\n",
       "16     Thriller       16\n",
       "17          War       17\n",
       "18      Western       18"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres = pd.read_csv(\"./ml-100k/u.genre\", \n",
    "                      header=None, \n",
    "                      sep='|', \n",
    "                      names=['Genre', 'GenreID'], \n",
    "                      engine='python')\n",
    "genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集概要\n",
    "文件包含：用户数量，电影数量，评分数量。\n",
    "\n",
    "共有943个用户参加评分，电影数量1682部， 100000条评分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>943</td>\n",
       "      <td>users</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1682</td>\n",
       "      <td>items</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100000</td>\n",
       "      <td>ratings</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number     Info\n",
       "0     943    users\n",
       "1    1682    items\n",
       "2  100000  ratings"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info = pd.read_csv(\"./ml-100k/u.info\", \n",
    "                      header=None, \n",
    "                      sep='\\s', \n",
    "                      names=['Number', 'Info'], \n",
    "                      engine='python')\n",
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 电影信息\n",
    "文件包含：电影ID，电影名称（含年份），电影放映日期，imdb评分链接， 电影类别\n",
    "\n",
    "数据中的格式：MovieID | MovieTitle | ReleaseDate | ImdbUrl | unknown | Action | Adventure | Animation | Children's | Comedy | Crime | Documentary | Drama | Fantasy  | Film-Noir | Horror | Musical | Mystery | Romance | Sci-Fi | Thriller | War | Western\n",
    "\n",
    "PS. 需要整理成 mid mtitle date genre(list)的形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>MovieTitle</th>\n",
       "      <th>Date</th>\n",
       "      <th>Url</th>\n",
       "      <th>unknown</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children's'</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>...</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MovieID         MovieTitle         Date  \\\n",
       "0        1   Toy Story (1995)  01-Jan-1995   \n",
       "1        2   GoldenEye (1995)  01-Jan-1995   \n",
       "2        3  Four Rooms (1995)  01-Jan-1995   \n",
       "3        4  Get Shorty (1995)  01-Jan-1995   \n",
       "4        5     Copycat (1995)  01-Jan-1995   \n",
       "\n",
       "                                                 Url  unknown  Action  \\\n",
       "0  http://us.imdb.com/M/title-exact?Toy%20Story%2...        0       0   \n",
       "1  http://us.imdb.com/M/title-exact?GoldenEye%20(...        0       1   \n",
       "2  http://us.imdb.com/M/title-exact?Four%20Rooms%...        0       0   \n",
       "3  http://us.imdb.com/M/title-exact?Get%20Shorty%...        0       1   \n",
       "4  http://us.imdb.com/M/title-exact?Copycat%20(1995)        0       0   \n",
       "\n",
       "   Adventure  Animation  Children's'  Comedy  ...  Fantasy  Film-Noir  Horror  \\\n",
       "0          0          1            1       1  ...        0          0       0   \n",
       "1          1          0            0       0  ...        0          0       0   \n",
       "2          0          0            0       0  ...        0          0       0   \n",
       "3          0          0            0       1  ...        0          0       0   \n",
       "4          0          0            0       0  ...        0          0       0   \n",
       "\n",
       "   Musical  Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
       "0        0        0        0       0         0    0        0  \n",
       "1        0        0        0       0         1    0        0  \n",
       "2        0        0        0       0         1    0        0  \n",
       "3        0        0        0       0         0    0        0  \n",
       "4        0        0        0       0         1    0        0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_title= ['MovieID', 'MovieTitle', 'Date','Url', 'unknown', \n",
    "               'Action', 'Adventure', 'Animation', 'Children\\'s\\'',\n",
    "               'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
    "               'Film-Noir', 'Horror', 'Musical', 'Mystery','Romance',\n",
    "               'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "lattr1 = [0, 1, 2, 4]\n",
    "lattr2 = [i for i in range(5, 24)]\n",
    "\n",
    "movies = pd.read_csv(\"./ml-100k/u.item\", \n",
    "                      header=None, \n",
    "                      sep='|', \n",
    "                      usecols=lattr1+lattr2,\n",
    "                      names=movies_title, \n",
    "                      engine='python')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 职业列表\n",
    "文件包含：多种职业\n",
    "\n",
    "PS. 整理成 Oid(0-20)的形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>administrator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>artist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doctor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>educator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>executive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>healthcare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>homemaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lawyer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>librarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>programmer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>salesman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>student</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>technician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>writer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Occupation\n",
       "0   administrator\n",
       "1          artist\n",
       "2          doctor\n",
       "3        educator\n",
       "4        engineer\n",
       "5   entertainment\n",
       "6       executive\n",
       "7      healthcare\n",
       "8       homemaker\n",
       "9          lawyer\n",
       "10      librarian\n",
       "11      marketing\n",
       "12           none\n",
       "13          other\n",
       "14     programmer\n",
       "15        retired\n",
       "16       salesman\n",
       "17      scientist\n",
       "18        student\n",
       "19     technician\n",
       "20         writer"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occupation = pd.read_csv(\"./ml-100k/u.occupation\", \n",
    "                      header=None, \n",
    "                      sep='\\s', \n",
    "                      names=['Occupation'], \n",
    "                      engine='python')\n",
    "occupation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用户信息\n",
    "文件包含：用户ID，用户年龄，用户性别，用户职业，用户邮编\n",
    "\n",
    "数据中的格式：UserID | Age | Gender | Occupation | ZipCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>ZipCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>85711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>94043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>32067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>43537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>15213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  Age Gender  Occupation ZipCode\n",
       "0       1   24      M  technician   85711\n",
       "1       2   53      F       other   94043\n",
       "2       3   23      M      writer   32067\n",
       "3       4   24      M  technician   43537\n",
       "4       5   33      F       other   15213"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = pd.read_csv(\"./ml-100k/u.user\", \n",
    "                      header=None, \n",
    "                      sep='|', \n",
    "                      names=['UserID', 'Age', 'Gender', 'Occupation', 'ZipCode'], \n",
    "                      engine='python')\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理\n",
    "\n",
    "- UserID, MovieID不变\n",
    "- Occupation处理成ID形式（0-20）\n",
    "- Genre\n",
    "- title忽略\n",
    "- Age\n",
    "- Gender转变为0和1\n",
    "- zipcode\n",
    "\n",
    "- rating是target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理评分信息\n",
    "4-5分为1， 0-3为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>TimeStamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>0</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>0</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>0</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  TimeStamp\n",
       "0     196      242       0  881250949\n",
       "1     186      302       0  891717742\n",
       "2      22      377       0  878887116\n",
       "3     244       51       0  880606923\n",
       "4     166      346       0  886397596"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_map = {5:1, 4:1, 3:0, 2:0, 1:0}\n",
    "ratings['Rating'] = ratings['Rating'].map(rating_map)\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理用户信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>ZipCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  Age  Gender  Occupation  ZipCode\n",
       "0       1   14       1          19      761\n",
       "1       2   43       0          13       16\n",
       "2       3   13       1          20      349\n",
       "3       4   14       1          19      241\n",
       "4       5   23       0          13      395"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将age值转化为连续的数字\n",
    "age_map = {val:ii for ii,val in enumerate(set(users['Age']))}\n",
    "users['Age'] = users['Age'].map(age_map)\n",
    "\n",
    "# 将zipcode值转化为连续的数字\n",
    "zip_map = {val:ii for ii,val in enumerate(set(users['ZipCode']))}\n",
    "users['ZipCode'] = users['ZipCode'].map(zip_map)\n",
    "\n",
    "# 将F转化为0，M转化为1\n",
    "if users['Gender'].dtype != 'int64':\n",
    "    gender_map = {'F': 0, 'M': 1}\n",
    "    users['Gender'] = users['Gender'].map(gender_map)\n",
    "\n",
    "# 将各个Occupation转化为对应的ID\n",
    "if users['Occupation'].dtype != 'int64':\n",
    "    occupation_map = {}\n",
    "    for index, row in occupation.iterrows():\n",
    "        occupation_map[row[0].lower()] = index\n",
    "    users['Occupation'] = users['Occupation'].map(occupation_map)\n",
    "\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理电影信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>MovieTitle</th>\n",
       "      <th>Date</th>\n",
       "      <th>Url</th>\n",
       "      <th>unknown</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children's'</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>...</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MovieID         MovieTitle         Date  \\\n",
       "2        3  Four Rooms (1995)  01-Jan-1995   \n",
       "1        2   GoldenEye (1995)  01-Jan-1995   \n",
       "\n",
       "                                                 Url  unknown  Action  \\\n",
       "2  http://us.imdb.com/M/title-exact?Four%20Rooms%...        0       0   \n",
       "1  http://us.imdb.com/M/title-exact?GoldenEye%20(...        0       1   \n",
       "\n",
       "   Adventure  Animation  Children's'  Comedy  ...  Fantasy  Film-Noir  Horror  \\\n",
       "2          0          0            0       0  ...        0          0       0   \n",
       "1          1          0            0       0  ...        0          0       0   \n",
       "\n",
       "   Musical  Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
       "2        0        0        0       0         1    0        0  \n",
       "1        0        0        0       0         1    0        0  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_map = {5: 1, 4: 1, 3: 0, 2: 0, 1: 0}\n",
    "# movies['Rating'] = movies['Rating'].map(rating_map)\n",
    "a = movies[(movies.MovieID == 3)]\n",
    "b = movies[(movies.MovieID == 2)]\n",
    "c = pd.concat([a, b])\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集处理代码\n",
    "创建用户相似矩阵，筛选出相似度最高的用户，挑选其中评分最高的电影。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcess:\n",
    "    def __init__(self, dataFile):\n",
    "        self.genreFile = \"./ml-100k/u.genre\"\n",
    "        self.itemFile = \"./ml-100k/u.item\"\n",
    "        self.userFile = \"./ml-100k/u.user\"\n",
    "        self.infoFile = \"./ml-100k/u.info\"\n",
    "        self.OcptFile = \"./ml-100k/u.occupation\"\n",
    "        self.dataFile = dataFile\n",
    "\n",
    "    def getRating(self):\n",
    "        ratings = pd.read_csv(\n",
    "            self.dataFile,\n",
    "            header=None,\n",
    "            sep='\\s',\n",
    "            names=['UserID', 'MovieID', 'Rating', 'TimeStamp'],\n",
    "            engine='python')\n",
    "        ratings = ratings[['UserID', 'MovieID', 'Rating']]\n",
    "        return ratings\n",
    "    \n",
    "    def getLrRating(self):\n",
    "        ratings = pd.read_csv(\n",
    "            self.dataFile,\n",
    "            header=None,\n",
    "            sep='\\s',\n",
    "            names=['UserID', 'MovieID', 'Rating', 'TimeStamp'],\n",
    "            engine='python')\n",
    "        ratings = ratings[['UserID', 'MovieID', 'Rating']]    \n",
    "#         ratings['Rating'] = ratings['Rating'].map({5:1, 4:1, 3:0, 2:0, 1:0})\n",
    "        return ratings\n",
    "\n",
    "    def getGenre(self):\n",
    "        genres = pd.read_csv(self.genreFile,\n",
    "                             header=None,\n",
    "                             sep='|',\n",
    "                             names=['Genre', 'GenreID'],\n",
    "                             engine='python')\n",
    "        return genres\n",
    "\n",
    "    def getInfo(self):\n",
    "        info = pd.read_csv(self.infoFile,\n",
    "                           header=None,\n",
    "                           sep='\\s',\n",
    "                           names=['Number', 'Info'],\n",
    "                           engine='python')\n",
    "        return info\n",
    "\n",
    "    def getMovies(self):\n",
    "        movies_title = [\n",
    "            'MovieID', 'MovieTitle', 'Date', 'Url', 'unknown', 'Action',\n",
    "            'Adventure', 'Animation', 'Children\\'s\\'', 'Comedy', 'Crime',\n",
    "            'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror',\n",
    "            'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War',\n",
    "            'Western'\n",
    "        ]\n",
    "\n",
    "        lattr1 = [0, 1, 2, 4]\n",
    "        lattr2 = [i for i in range(5, 24)]\n",
    "        movies = pd.read_csv(self.itemFile,\n",
    "                             header=None,\n",
    "                             sep='|',\n",
    "                             usecols=lattr1 + lattr2,\n",
    "                             names=movies_title,\n",
    "                             engine='python')\n",
    "        movies_title = [\n",
    "            'MovieID', 'MovieTitle', 'unknown', 'Action',\n",
    "            'Adventure', 'Animation', 'Children\\'s\\'', 'Comedy', 'Crime',\n",
    "            'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror',\n",
    "            'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War',\n",
    "            'Western'\n",
    "        ]\n",
    "        movies = movies[movies_title]\n",
    "        return movies\n",
    "    \n",
    "    def getMoviesInfo(self):\n",
    "        movies = self.merge_rating_movies()\n",
    "        movies = movies.drop([\"Rating\"], axis=1)\n",
    "        movieDict = {}\n",
    "        for index, row in movies.iterrows():\n",
    "            if row[1] not in movieDict.keys():\n",
    "                movieDict[row[1]] = [row.values]\n",
    "            else:\n",
    "                movieDict[row[1]].append(row.values)\n",
    "        return movieDict\n",
    "\n",
    "    def getUser(self):\n",
    "        occupation = pd.read_csv(self.OcptFile,\n",
    "                                 header=None,\n",
    "                                 sep='\\s',\n",
    "                                 names=['Occupation'],\n",
    "                                 engine='python')\n",
    "\n",
    "        users = pd.read_csv(\n",
    "            self.userFile,\n",
    "            header=None,\n",
    "            sep='|',\n",
    "            names=['UserID', 'Age', 'Gender', 'Occupation', 'ZipCode'],\n",
    "            engine='python')\n",
    "        # 将age值转化为连续的数字\n",
    "        age_map = {val: ii for ii, val in enumerate(set(users['Age']))}\n",
    "        users['Age'] = users['Age'].map(age_map)\n",
    "\n",
    "        # 将zipcode值转化为连续的数字\n",
    "        zip_map = {val: ii for ii, val in enumerate(set(users['ZipCode']))}\n",
    "        users['ZipCode'] = users['ZipCode'].map(zip_map)\n",
    "\n",
    "        # 将F转化为0，M转化为1\n",
    "        if users['Gender'].dtype != 'int64':\n",
    "            gender_map = {'F': 0, 'M': 1}\n",
    "            users['Gender'] = users['Gender'].map(gender_map)\n",
    "\n",
    "        # 将各个Occupation转化为对应的ID\n",
    "        if users['Occupation'].dtype != 'int64':\n",
    "            occupation_map = {}\n",
    "            for index, row in occupation.iterrows():\n",
    "                occupation_map[row[0].lower()] = index\n",
    "            users['Occupation'] = users['Occupation'].map(occupation_map)\n",
    "\n",
    "        return users\n",
    "\n",
    "    def merge_rating_movies(self):\n",
    "        rating = self.getRating()\n",
    "        movie = self.getMovies()\n",
    "        movie = movie.drop('MovieTitle', 1)\n",
    "        user = self.getUser()\n",
    "        temp = pd.merge(rating, user, on='UserID')\n",
    "        new = pd.merge(temp, movie, on='MovieID')\n",
    "        return new\n",
    "    \n",
    "    def merge_lrRating_movies(self):\n",
    "        rating = self.getLrRating()\n",
    "        movie = self.getMovies()\n",
    "        movie = movie.drop('MovieTitle', 1)\n",
    "        user = self.getUser()\n",
    "        temp = pd.merge(rating, user, on='UserID')\n",
    "        new = pd.merge(temp, movie, on='MovieID')\n",
    "        return new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-based CF\n",
    "创建用户相似矩阵(未实现,目前用字典代替)，筛选出相似度最高的用户，挑选其中评分最高的电影。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserCF:\n",
    "    def __init__(self, data, trainData, testData, logReg=None, cs=0):\n",
    "        if logReg:\n",
    "            self.lr = logReg\n",
    "        else:\n",
    "            self.lr = None\n",
    "        self.cs = cs\n",
    "        self.Data = data\n",
    "        self.trainData = trainData\n",
    "        self.testData = testData\n",
    "        self.MovieDict = self.classifyMovie(data)\n",
    "        self.trainMovieDict = self.classifyMovie(trainData)\n",
    "        self.testMovieDict = self.classifyMovie(testData)\n",
    "        self.movieInfo = self.Data.getMoviesInfo()\n",
    "    \n",
    "    def coldStart(self, lr):\n",
    "        ratings = self.Data.getRating()\n",
    "        movies = self.Data.getMovies().drop(['MovieTitle'], axis=1)\n",
    "        users = self.Data.getUser()\n",
    "        \n",
    "        userNum = users['UserID'].values.argmax() + 1\n",
    "        movieNum = movies['MovieID'].values.argmax() + 1\n",
    "        \n",
    "        # 创建一个字典存 每个user看过的电影， 格式 {userID： movieList[]}\n",
    "        # 被评论超过平均值次数的movie列为热门电影\n",
    "        uDict = {}\n",
    "        popular = []\n",
    "        result = []  # 所有评论过的movie\n",
    "        \n",
    "        uTemp = pd.merge(ratings, users, on='UserID')\n",
    "        for uid in range(1, userNum+1):\n",
    "            temp = uTemp[(uTemp.UserID == uid)]\n",
    "            uDict[uid] = temp['MovieID'].values\n",
    "            result += temp['MovieID'].values.tolist()\n",
    "        \n",
    "        counter = Counter(result)\n",
    "        maxCommented = max(counter.values())\n",
    "        minCommented = min(counter.values())\n",
    "        avgCommented = (maxCommented + minCommented) / 2\n",
    "        for mid in counter.keys():\n",
    "            if counter[mid] >= avgCommented:\n",
    "                popular.append(mid)\n",
    "        \n",
    "        # new Ratings needs to insert\n",
    "        nrLs = [] # new rating list\n",
    "        for pMid in popular:\n",
    "            for uid in uDict.keys():\n",
    "                if pMid not in uDict[uid]:\n",
    "                    nrLs.append([uid, pMid, 0])\n",
    "        nRatings = pd.DataFrame(nrLs, columns=['UserID', 'MovieID', 'Rating'])\n",
    "        dataSet = pd.merge(nRatings, users, on='UserID')\n",
    "        dataSet = pd.merge(dataSet, movies, on='MovieID')\n",
    "        \n",
    "        predX = dataSet[['UserID', 'MovieID', 'Age', 'Gender', 'Occupation', 'ZipCode']]\n",
    "        predY = lr.predict(predX)\n",
    "        \n",
    "        nRatings = nRatings.drop(['Rating'], axis = 1)\n",
    "        nRatings['Rating'] = predY\n",
    "        return nRatings\n",
    "    \n",
    "    def classifyMovie(self, data):\n",
    "        movieDict = {}\n",
    "        df_rate = data.getRating()\n",
    "        if self.cs == 1:\n",
    "            nRatings = self.coldStart(self.lr)\n",
    "            df_rate = pd.concat([df_rate, nRatings])\n",
    "        df_movie = data.getMovies()\n",
    "        rating_movies = pd.merge(df_rate, df_movie, on='MovieID').sort_values('UserID')\n",
    "       \n",
    "        for index, row in rating_movies.iterrows():\n",
    "            if not row[\"UserID\"] in movieDict.keys():\n",
    "                movieDict[row[\"UserID\"]] = {row[\"MovieID\"]: (row[\"Rating\"], row[\"MovieTitle\"])}\n",
    "            else:\n",
    "                movieDict[row[\"UserID\"]][row[\"MovieID\"]] = (row[\"Rating\"], row[\"MovieTitle\"])\n",
    "        return movieDict\n",
    "    \n",
    "    def euclidean(self, user1, user2):\n",
    "        # movieDict = self.classifyMovie()\n",
    "        # pull out two users from movieDict\n",
    "        user1_data = self.trainMovieDict[user1]\n",
    "        user2_data = self.trainMovieDict[user2]\n",
    "        distance = 0\n",
    "        # cal euclidean distance\n",
    "        for key in user1_data.keys():\n",
    "            if key in user2_data.keys():\n",
    "                # the smaller, the more simularity\n",
    "                distance += pow(float(user1_data[key][0])-float(user2_data[key][0]),2)\n",
    "        return 1 / (1 + math.sqrt(distance))\n",
    "   \n",
    "    # 这里应该用一张 维度是(userNum, userNum)的矩阵去记录每个用户的相似度(未完成)\n",
    "    def topSim(self, userID):\n",
    "        res = []\n",
    "        for uid in self.MovieDict.keys():\n",
    "            if not uid == userID:\n",
    "                similarity = self.euclidean(userID,uid)\n",
    "                res.append((uid,similarity))\n",
    "        res.sort(key=lambda val:val[1])\n",
    "        return res\n",
    "    \n",
    "    # 预测可以根据年份去优先预测比较新的高分电影（并未实现）\n",
    "    def predict(self, user, N, K, threshold):\n",
    "        top_sim_users = self.topSim(user)[:K]\n",
    "        rec = []\n",
    "        rec_list = []\n",
    "        for sUserInfo in top_sim_users:\n",
    "            sUser = sUserInfo[0]\n",
    "            items = self.trainMovieDict[sUser]\n",
    "            for item in items.keys():\n",
    "                if item not in self.trainMovieDict[user].keys():\n",
    "                    if items[item][0] >= threshold:\n",
    "                        rec_list.append(item)\n",
    "                        rec.append((item,items[item]))\n",
    "        rec.sort(key=lambda val:val[1],reverse=True)\n",
    "        rec_list = list(set(rec_list))\n",
    "        rec = list(set(rec))\n",
    "        return random.sample(rec, N), rec_list\n",
    "    \n",
    "    def lrPredict(self, user, N, K, threshold):\n",
    "        movies = self.Data.getMovies().drop(['MovieTitle'], axis=1)\n",
    "        users = self.Data.getUser()\n",
    "        top_sim_users = self.topSim(user)[:K]\n",
    "        \n",
    "        recMovies = []\n",
    "        result = []\n",
    "        rec_list = []\n",
    "        for sUserInfo in top_sim_users:\n",
    "            sUser = sUserInfo[0]\n",
    "            items = self.trainMovieDict[sUser]\n",
    "            for item in items.keys():\n",
    "                if item not in self.trainMovieDict[user].keys():\n",
    "                    if items[item][0] >= threshold:\n",
    "                        recMovies.append([user, item])\n",
    "            lrRatings = pd.DataFrame(recMovies, columns=['UserID', 'MovieID'])\n",
    "            dataSet = pd.merge(lrRatings, users, on='UserID')\n",
    "            dataSet = pd.merge(dataSet, movies, on='MovieID')\n",
    "            predX = dataSet[['UserID', 'MovieID', 'Age', 'Gender', 'Occupation', 'ZipCode']]\n",
    "            predY = self.lr.predict(predX)\n",
    "            movieL = predX[['UserID', 'MovieID']].copy()\n",
    "            movieL['Rating'] = predY\n",
    "            movieL = movieL[(movieL.Rating >= threshold)]['MovieID'].values\n",
    "            \n",
    "            superMovieL = self.trainMovieDict[sUser].keys()\n",
    "            movieL = set(movieL).intersection(set(superMovieL))\n",
    "            movieL = list(movieL)\n",
    "            for movie in movieL:\n",
    "                movie_title = self.trainMovieDict[sUser][movie][1]\n",
    "                result.append((movie, movie_title))\n",
    "                rec_list.append(movie)\n",
    "\n",
    "        rec_list = list(set(rec_list))\n",
    "        result = list(set(result))\n",
    "        result.sort(key=lambda val:val[1],reverse=True)\n",
    "        return random.sample(result, N), rec_list\n",
    "    \n",
    "    # 评估正确率 precision = R(u) 和 T(u) 重合个数 / R(U)\n",
    "    # R(u): 在训练集上对用户u推荐N个物品, T(u): 用户u在测试集上评价过的物品集合\n",
    "    # N是推荐电影数量, N = R(U)\n",
    "    # 需要分测试集和训练集去计算, 因为推荐系统不会推荐用户评过分的电影\n",
    "    def evaluation(self, N, K, threshold):\n",
    "        count = 0\n",
    "        total = 0\n",
    "        rAll = 0\n",
    "        trainMovieDict = self.trainMovieDict\n",
    "        testMovieDict = self.testMovieDict\n",
    "        for uid in trainMovieDict.keys():\n",
    "            if uid not in testMovieDict.keys():\n",
    "                continue\n",
    "            t = 0\n",
    "            pred, _ = self.predict(uid, N, K, threshold)\n",
    "            for info in pred:\n",
    "                if info[0] in testMovieDict[uid].keys():\n",
    "                    t += 1\n",
    "            p = t / N\n",
    "            total += p\n",
    "            count += 1\n",
    "            rAll += len(testMovieDict[uid])\n",
    "        return total / count, t / rAll\n",
    "\n",
    "    def lrEvaluation(self, N, K, threshold):\n",
    "        count = 0\n",
    "        total = 0\n",
    "        rAll = 0\n",
    "        trainMovieDict = self.trainMovieDict\n",
    "        testMovieDict = self.testMovieDict\n",
    "        for uid in trainMovieDict.keys():\n",
    "            if uid not in testMovieDict.keys():\n",
    "                continue\n",
    "            t = 0\n",
    "            pred = self.lrPredict(uid, N, K, threshold)\n",
    "            for info in pred:\n",
    "                if info[0] in testMovieDict[uid].keys():\n",
    "                    t += 1\n",
    "            p = t / N\n",
    "            total += p\n",
    "            count += 1\n",
    "            rAll += len(testMovieDict[uid])\n",
    "        return total / count, t / rAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataProcess('./ml-100k/u.data')\n",
    "trainData = DataProcess('./ml-100k/u1.base')\n",
    "testData = DataProcess('./ml-100k/u1.test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "userCF = UserCF(data, trainData, testData, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(333, 'Game, The (1997)'),\n",
       "  (68, 'Crow, The (1994)'),\n",
       "  (31, 'Crimson Tide (1995)'),\n",
       "  (732, 'Dave (1993)'),\n",
       "  (655, 'Stand by Me (1986)'),\n",
       "  (288, 'Scream (1996)'),\n",
       "  (396, 'Serial Mom (1994)'),\n",
       "  (382, 'Adventures of Priscilla, Queen of the Desert, The (1994)'),\n",
       "  (235, 'Mars Attacks! (1996)'),\n",
       "  (227, 'Star Trek VI: The Undiscovered Country (1991)')],\n",
       " [1,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  17,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  27,\n",
       "  28,\n",
       "  30,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  38,\n",
       "  40,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  47,\n",
       "  48,\n",
       "  52,\n",
       "  53,\n",
       "  55,\n",
       "  56,\n",
       "  58,\n",
       "  59,\n",
       "  62,\n",
       "  63,\n",
       "  64,\n",
       "  65,\n",
       "  66,\n",
       "  67,\n",
       "  68,\n",
       "  70,\n",
       "  72,\n",
       "  74,\n",
       "  77,\n",
       "  79,\n",
       "  81,\n",
       "  82,\n",
       "  83,\n",
       "  86,\n",
       "  87,\n",
       "  88,\n",
       "  89,\n",
       "  90,\n",
       "  91,\n",
       "  92,\n",
       "  93,\n",
       "  94,\n",
       "  96,\n",
       "  97,\n",
       "  98,\n",
       "  99,\n",
       "  100,\n",
       "  102,\n",
       "  106,\n",
       "  107,\n",
       "  109,\n",
       "  111,\n",
       "  116,\n",
       "  118,\n",
       "  121,\n",
       "  122,\n",
       "  123,\n",
       "  124,\n",
       "  126,\n",
       "  127,\n",
       "  128,\n",
       "  130,\n",
       "  131,\n",
       "  132,\n",
       "  133,\n",
       "  134,\n",
       "  136,\n",
       "  137,\n",
       "  140,\n",
       "  142,\n",
       "  143,\n",
       "  144,\n",
       "  145,\n",
       "  147,\n",
       "  148,\n",
       "  149,\n",
       "  150,\n",
       "  151,\n",
       "  152,\n",
       "  153,\n",
       "  154,\n",
       "  155,\n",
       "  156,\n",
       "  157,\n",
       "  160,\n",
       "  167,\n",
       "  168,\n",
       "  169,\n",
       "  170,\n",
       "  171,\n",
       "  173,\n",
       "  175,\n",
       "  176,\n",
       "  177,\n",
       "  178,\n",
       "  179,\n",
       "  180,\n",
       "  181,\n",
       "  182,\n",
       "  183,\n",
       "  184,\n",
       "  185,\n",
       "  186,\n",
       "  187,\n",
       "  188,\n",
       "  190,\n",
       "  191,\n",
       "  192,\n",
       "  193,\n",
       "  194,\n",
       "  195,\n",
       "  196,\n",
       "  197,\n",
       "  198,\n",
       "  199,\n",
       "  200,\n",
       "  201,\n",
       "  202,\n",
       "  203,\n",
       "  204,\n",
       "  205,\n",
       "  206,\n",
       "  208,\n",
       "  209,\n",
       "  210,\n",
       "  211,\n",
       "  213,\n",
       "  215,\n",
       "  216,\n",
       "  217,\n",
       "  218,\n",
       "  219,\n",
       "  222,\n",
       "  223,\n",
       "  226,\n",
       "  227,\n",
       "  228,\n",
       "  229,\n",
       "  230,\n",
       "  232,\n",
       "  234,\n",
       "  235,\n",
       "  238,\n",
       "  239,\n",
       "  240,\n",
       "  241,\n",
       "  243,\n",
       "  248,\n",
       "  250,\n",
       "  251,\n",
       "  255,\n",
       "  260,\n",
       "  262,\n",
       "  265,\n",
       "  268,\n",
       "  269,\n",
       "  270,\n",
       "  271,\n",
       "  272,\n",
       "  273,\n",
       "  274,\n",
       "  275,\n",
       "  276,\n",
       "  281,\n",
       "  282,\n",
       "  283,\n",
       "  285,\n",
       "  286,\n",
       "  288,\n",
       "  291,\n",
       "  293,\n",
       "  295,\n",
       "  296,\n",
       "  297,\n",
       "  298,\n",
       "  300,\n",
       "  301,\n",
       "  302,\n",
       "  303,\n",
       "  305,\n",
       "  307,\n",
       "  310,\n",
       "  316,\n",
       "  317,\n",
       "  318,\n",
       "  320,\n",
       "  322,\n",
       "  323,\n",
       "  324,\n",
       "  325,\n",
       "  326,\n",
       "  327,\n",
       "  328,\n",
       "  329,\n",
       "  331,\n",
       "  332,\n",
       "  333,\n",
       "  334,\n",
       "  335,\n",
       "  336,\n",
       "  339,\n",
       "  340,\n",
       "  343,\n",
       "  344,\n",
       "  345,\n",
       "  346,\n",
       "  347,\n",
       "  352,\n",
       "  354,\n",
       "  357,\n",
       "  358,\n",
       "  364,\n",
       "  366,\n",
       "  367,\n",
       "  378,\n",
       "  381,\n",
       "  382,\n",
       "  384,\n",
       "  385,\n",
       "  386,\n",
       "  392,\n",
       "  393,\n",
       "  396,\n",
       "  399,\n",
       "  401,\n",
       "  402,\n",
       "  405,\n",
       "  407,\n",
       "  415,\n",
       "  416,\n",
       "  418,\n",
       "  419,\n",
       "  420,\n",
       "  421,\n",
       "  422,\n",
       "  423,\n",
       "  425,\n",
       "  427,\n",
       "  428,\n",
       "  429,\n",
       "  430,\n",
       "  431,\n",
       "  432,\n",
       "  433,\n",
       "  434,\n",
       "  435,\n",
       "  436,\n",
       "  440,\n",
       "  443,\n",
       "  444,\n",
       "  445,\n",
       "  447,\n",
       "  448,\n",
       "  451,\n",
       "  455,\n",
       "  458,\n",
       "  462,\n",
       "  463,\n",
       "  468,\n",
       "  469,\n",
       "  470,\n",
       "  471,\n",
       "  472,\n",
       "  473,\n",
       "  474,\n",
       "  475,\n",
       "  476,\n",
       "  477,\n",
       "  478,\n",
       "  479,\n",
       "  480,\n",
       "  483,\n",
       "  484,\n",
       "  488,\n",
       "  489,\n",
       "  491,\n",
       "  492,\n",
       "  494,\n",
       "  496,\n",
       "  497,\n",
       "  498,\n",
       "  500,\n",
       "  501,\n",
       "  502,\n",
       "  503,\n",
       "  504,\n",
       "  505,\n",
       "  507,\n",
       "  508,\n",
       "  509,\n",
       "  510,\n",
       "  511,\n",
       "  512,\n",
       "  514,\n",
       "  515,\n",
       "  517,\n",
       "  518,\n",
       "  519,\n",
       "  520,\n",
       "  521,\n",
       "  522,\n",
       "  523,\n",
       "  524,\n",
       "  525,\n",
       "  526,\n",
       "  527,\n",
       "  528,\n",
       "  529,\n",
       "  530,\n",
       "  531,\n",
       "  535,\n",
       "  537,\n",
       "  538,\n",
       "  546,\n",
       "  547,\n",
       "  549,\n",
       "  550,\n",
       "  553,\n",
       "  554,\n",
       "  558,\n",
       "  563,\n",
       "  564,\n",
       "  565,\n",
       "  566,\n",
       "  568,\n",
       "  573,\n",
       "  576,\n",
       "  578,\n",
       "  582,\n",
       "  588,\n",
       "  589,\n",
       "  591,\n",
       "  603,\n",
       "  604,\n",
       "  607,\n",
       "  610,\n",
       "  611,\n",
       "  614,\n",
       "  615,\n",
       "  616,\n",
       "  617,\n",
       "  619,\n",
       "  620,\n",
       "  625,\n",
       "  627,\n",
       "  628,\n",
       "  629,\n",
       "  631,\n",
       "  633,\n",
       "  635,\n",
       "  636,\n",
       "  638,\n",
       "  640,\n",
       "  641,\n",
       "  642,\n",
       "  644,\n",
       "  645,\n",
       "  646,\n",
       "  647,\n",
       "  648,\n",
       "  651,\n",
       "  652,\n",
       "  653,\n",
       "  654,\n",
       "  655,\n",
       "  656,\n",
       "  657,\n",
       "  658,\n",
       "  659,\n",
       "  660,\n",
       "  661,\n",
       "  662,\n",
       "  664,\n",
       "  665,\n",
       "  668,\n",
       "  671,\n",
       "  673,\n",
       "  675,\n",
       "  676,\n",
       "  678,\n",
       "  679,\n",
       "  682,\n",
       "  684,\n",
       "  685,\n",
       "  686,\n",
       "  689,\n",
       "  690,\n",
       "  692,\n",
       "  698,\n",
       "  699,\n",
       "  707,\n",
       "  708,\n",
       "  709,\n",
       "  710,\n",
       "  712,\n",
       "  713,\n",
       "  715,\n",
       "  716,\n",
       "  717,\n",
       "  719,\n",
       "  720,\n",
       "  723,\n",
       "  727,\n",
       "  729,\n",
       "  730,\n",
       "  732,\n",
       "  735,\n",
       "  739,\n",
       "  740,\n",
       "  742,\n",
       "  743,\n",
       "  745,\n",
       "  746,\n",
       "  747,\n",
       "  748,\n",
       "  750,\n",
       "  754,\n",
       "  755,\n",
       "  763,\n",
       "  765,\n",
       "  771,\n",
       "  772,\n",
       "  775,\n",
       "  778,\n",
       "  781,\n",
       "  790,\n",
       "  792,\n",
       "  794,\n",
       "  806,\n",
       "  807,\n",
       "  810,\n",
       "  812,\n",
       "  815,\n",
       "  821,\n",
       "  825,\n",
       "  827])"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userCF.lrPredict(30, 10, 10, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 机器学习 拆分数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "用逻辑回归预测missing rating value 冷启动"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kyrie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kyrie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.4359"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainLr = trainData.merge_lrRating_movies()\n",
    "trainX = trainLr[['UserID', 'MovieID', 'Age', 'Gender', 'Occupation', 'ZipCode']]\n",
    "trainY = trainLr['Rating']\n",
    "\n",
    "testLr = testData.merge_lrRating_movies()\n",
    "testX = testLr[['UserID', 'MovieID', 'Age', 'Gender', 'Occupation', 'ZipCode']]\n",
    "testY = testLr['Rating']\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(trainX, trainY.ravel())\n",
    "predY = lr.predict(testX)\n",
    "# acc_log = round(lr.score(trainX, trainY) * 100, 2)\n",
    "mse = mean_squared_error(testY, predY)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# userCF_lr = UserCF(data, trainData, testData, lr)\n",
    "userCF = UserCF(data, trainData, testData, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "evaluation() missing 1 required positional argument: 'threshold'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-570-0775121e61bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# recommend without prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0muserCF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: evaluation() missing 1 required positional argument: 'threshold'"
     ]
    }
   ],
   "source": [
    "# recommend without prediction\n",
    "userCF.evaluation(10, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# recommend with predicition\n",
    "userCF.lrEvaluation(10, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# userCF start with lr\n",
    "userCF_lr = UserCF(data, trainData, testData, lr, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommend without prediction\n",
    "userCF_lr.evaluation(10, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommend with predicition\n",
    "# userCF_lr.lrEvaluation(lr, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "userCF = UserCF(data, trainData, testData, lr)\n",
    "# userCF_lr = UserCF(data, trainData, testData, lr)\n",
    "\n",
    "_, rec_list = userCF.predict(500,10,10,4)\n",
    "_, rec_list_lr = userCF.lrPredict(500,10,10,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 5, 6, 11, 12, 14, 17, 20, 21, 22, 23, 24, 26, 27, 29, 32, 33, 34, 38, 40, 46, 47, 48, 51, 53, 54, 55, 63, 64, 65, 66, 67, 68, 71, 73, 76, 79, 80, 81, 85, 86, 87, 90, 91, 92, 95, 96, 99, 101, 102, 105, 107, 110, 114, 123, 124, 126, 127, 128, 131, 132, 136, 137, 138, 139, 140, 141, 142, 144, 148, 149, 150, 152, 153, 154, 155, 156, 157, 162, 163, 165, 166, 167, 169, 173, 176, 177, 178, 180, 184, 185, 186, 187, 188, 190, 191, 192, 193, 194, 195, 197, 198, 199, 200, 203, 205, 206, 207, 209, 213, 218, 219, 220, 221, 222, 225, 226, 227, 228, 229, 230, 231, 232, 233, 236, 239, 241, 248, 251, 254, 259, 260, 262, 265, 269, 270, 272, 273, 278, 280, 288, 290, 291, 292, 293, 296, 297, 302, 303, 305, 307, 310, 311, 312, 315, 317, 318, 320, 322, 326, 327, 331, 332, 333, 334, 339, 340, 343, 344, 345, 346, 347, 354, 355, 356, 357, 363, 364, 365, 366, 368, 372, 376, 378, 380, 384, 385, 388, 389, 391, 392, 395, 397, 399, 400, 401, 403, 404, 408, 410, 415, 416, 417, 418, 419, 420, 427, 428, 429, 430, 431, 432, 433, 435, 445, 447, 449, 450, 451, 452, 455, 463, 465, 468, 470, 474, 477, 478, 480, 481, 482, 484, 485, 488, 489, 490, 491, 492, 493, 495, 496, 497, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 510, 511, 515, 516, 518, 519, 520, 521, 523, 525, 526, 527, 528, 530, 538, 541, 542, 544, 547, 549, 550, 558, 560, 561, 564, 565, 566, 570, 571, 576, 577, 578, 579, 581, 585, 586, 587, 588, 591, 596, 597, 602, 603, 604, 606, 607, 608, 609, 610, 612, 613, 614, 616, 618, 620, 622, 623, 624, 625, 627, 628, 629, 631, 632, 633, 636, 637, 638, 642, 644, 645, 647, 648, 650, 651, 652, 654, 655, 657, 658, 659, 661, 663, 673, 676, 679, 684, 685, 686, 689, 690, 692, 693, 696, 697, 698, 702, 705, 707, 710, 712, 713, 716, 717, 720, 722, 723, 724, 725, 728, 730, 731, 732, 736, 746, 747, 748, 749, 750, 751, 754, 756, 761, 765, 769, 770, 774, 776, 778, 779, 783, 790, 792, 794, 795, 796, 802, 807, 809, 810, 812, 823, 825, 826, 837, 840, 842, 844, 847, 849, 862, 864, 865, 866, 867, 869, 873, 874, 875, 880, 896, 898, 900, 904, 905, 913, 915, 917, 918, 921, 923, 924, 926, 928, 929, 931, 932, 934, 936, 939, 941, 942, 943, 944, 949, 951, 952, 954, 955, 956, 959, 962, 965, 966, 967, 968, 969, 972, 975, 979, 980, 993, 1005, 1007, 1011, 1016, 1020, 1028, 1030, 1032, 1033, 1036, 1039, 1041, 1044, 1050, 1051, 1053, 1055, 1058, 1061, 1063, 1070, 1074, 1078, 1079, 1091, 1098, 1107, 1115, 1118, 1119, 1126, 1131, 1133, 1136, 1139, 1140, 1142, 1152, 1153, 1168, 1169, 1172, 1173, 1176, 1185, 1189, 1192, 1194, 1211, 1217, 1218, 1219, 1220, 1221, 1224, 1239, 1240, 1248, 1261, 1262, 1264, 1267, 1285, 1286, 1297, 1303, 1368, 1380, 1400, 1401, 1415, 1418, 1421, 1425, 1426, 1428, 1435, 1439, 1443, 1444, 1446, 1473, 1483, 1516, 1518, 1540, 1553, 1585, 1594, 1623, 1631, 1636, 1639, 1642, 1643, 1645, 1650, 1651]\n"
     ]
    }
   ],
   "source": [
    "print(rec_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 5, 6, 11, 12, 14, 17, 20, 21, 22, 23, 24, 26, 27, 29, 32, 33, 34, 38, 40, 46, 47, 48, 51, 53, 54, 55, 63, 64, 65, 66, 67, 68, 71, 73, 76, 79, 80, 81, 85, 86, 87, 90, 91, 92, 95, 96, 99, 101, 102, 105, 107, 110, 114, 123, 124, 126, 127, 128, 131, 132, 136, 137, 138, 139, 140, 141, 142, 144, 148, 149, 150, 152, 153, 154, 155, 156, 157, 162, 163, 165, 166, 167, 169, 173, 176, 177, 178, 180, 184, 185, 186, 187, 188, 190, 191, 192, 193, 194, 195, 197, 198, 199, 200, 203, 205, 206, 207, 209, 213, 218, 219, 220, 221, 222, 225, 226, 227, 228, 229, 230, 231, 232, 233, 236, 239, 241, 248, 251, 254, 259, 260, 262, 265, 269, 270, 272, 273, 278, 280, 288, 290, 291, 292, 293, 296, 297, 302, 303, 305, 307, 310, 311, 312, 315, 317, 318, 320, 322, 326, 327, 331, 332, 333, 334, 339, 340, 343, 344, 345, 346, 347, 354, 355, 356, 357, 363, 364, 365, 366, 368, 372, 376, 378, 380, 384, 385, 388, 389, 391, 392, 395, 397, 399, 400, 401, 403, 404, 408, 410, 415, 416, 417, 418, 419, 420, 427, 428, 429, 430, 431, 432, 433, 435, 445, 447, 449, 450, 451, 452, 455, 463, 465, 468, 470, 474, 477, 478, 480, 481, 482, 484, 485, 488, 489, 490, 491, 492, 493, 495, 496, 497, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 510, 511, 515, 516, 518, 519, 520, 521, 523, 525, 526, 527, 528, 530, 538, 541, 542, 544, 547, 549, 550, 558, 560, 561, 564, 565, 566, 570, 571, 576, 577, 578, 579, 581, 585, 586, 587, 588, 591, 596, 597, 602, 603, 604, 606, 607, 608, 609, 610, 612, 613, 614, 616, 618, 620, 622, 623, 624, 625, 627, 628, 629, 631, 632, 633, 636, 637, 638, 642, 644, 645, 647, 648, 650, 651, 652, 654, 655, 657, 658, 659, 661, 663, 673, 676, 679, 684, 685, 686, 689, 690, 692, 693, 696, 697, 698, 702, 705, 707, 710, 712, 713, 716, 717, 720, 722, 723, 724, 725, 728, 730, 731, 732, 736, 746, 747, 748, 749, 750, 751, 754, 756, 761, 765, 769, 770, 774, 776, 778, 779, 783, 790, 792, 794, 795, 796, 802, 807, 809, 810, 812, 823, 825, 826]\n"
     ]
    }
   ],
   "source": [
    "print(rec_list_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set_lr = userCF_lr.trainMovieDict\n",
    "# test_set_lr = userCF_lr.testMovieDict\n",
    "train_set = userCF.trainMovieDict\n",
    "test_set = userCF.testMovieDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommend_list 必须要在recommend函数里面另外返回一个like rec_list=[3,44,324,623,....]\n",
    "def Recall(train, test, N, K, method, lr=0):\n",
    "    hit = 0\n",
    "    all = 0\n",
    "    for user in train.keys():\n",
    "        if user not in test.keys():\n",
    "            continue\n",
    "        tu = test[user]\n",
    "        if lr==1:\n",
    "            _, recommend_list = method.lrPredict(user,N,K,4)\n",
    "        else:\n",
    "            _, recommend_list = method.predict(user,N,K,4)\n",
    "        for item in recommend_list:\n",
    "            if item in tu:\n",
    "                hit += 1\n",
    "        all += len(tu)\n",
    "    return hit/(all*1.0)\n",
    "\n",
    "def Precision(train, test, N, K, method, lr=0):\n",
    "    hit = 0\n",
    "    all = 0\n",
    "    for user in train.keys():\n",
    "        if user not in test.keys():\n",
    "            continue\n",
    "        tu = test[user]\n",
    "        if lr==1:\n",
    "            _, recommend_list = method.lrPredict(user, N, K, 4)\n",
    "        else:\n",
    "            _, recommend_list = method.predict(user, N, K, 4)\n",
    "#         recommend_list = get_recommendation(N, user, K, W, train)\n",
    "        for item in recommend_list:\n",
    "            if item in tu:\n",
    "                hit += 1\n",
    "            all += N\n",
    "    return hit/(all*1.0)\n",
    "\n",
    "\n",
    "def All_item(train):\n",
    "    all_items = set()\n",
    "    for user in train.keys():\n",
    "        for item in train[user]:\n",
    "            all_items.add(item)\n",
    "    return all_items\n",
    " \n",
    "def Coverage(train, test, N, K, method,all_items):\n",
    "    recommend_items = set()\n",
    "    for user in train.keys():\n",
    "        if method.lr:\n",
    "            _, recommend_list = method.lrPredict(user, N, K, 4)\n",
    "        else:\n",
    "            _, recommend_list = method.predict(user, N, K, 4)\n",
    "#         recommend_list = get_recommendation(N, user, K, W, train)\n",
    "        for item in recommend_list:\n",
    "            recommend_items.add(item)\n",
    "    return len(recommend_items)/(len(all_items)*1.0)\n",
    "\n",
    "def Item_popularity(train):\n",
    "    item_popularity = {}\n",
    "    for user, items in train.items():\n",
    "        for item in items:\n",
    "            if item not in item_popularity.keys():\n",
    "                item_popularity[item] = 0\n",
    "            item_popularity[item] += 1\n",
    "    return item_popularity\n",
    " \n",
    "def Popularity(train, test, N, K, recommend_list, item_popularity):  \n",
    "    ret = 0\n",
    "    n = 0\n",
    "    for user in train.keys():\n",
    "#         recommend_list = get_recommendation(N, user, K, W, train)\n",
    "        for item in recommend_list:\n",
    "            ret += np.log(1+item_popularity[item])\n",
    "            n += 1\n",
    "    return ret/(n*1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1\n",
    "K = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3257"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = Recall(train_set, test_set, N, K, userCF)\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = Recall(train_set, test_set, N, K, userCF, 1)\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = Precision(train_set, test_set, N, K, userCF)\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = Precision(train_set, test_set, N, K, userCF, 1)\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover = Coverage(train_set, test_set, N, K, userCF, All_item(train_set))\n",
    "cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_lr = Recall(train_set_lr, test_set_lr, 10, 10, rec_list_lr)\n",
    "precision_lr=Precision(train_set_lr, test_set_lr, 10, 10, rec_list_lr)\n",
    "cover_lr = Coverage(train_set_lr, test_set_lr, 10, 10, rec_list_lr,All_item(train_set_lr))\n",
    "popular_lr = Popularity(train_set_lr, test_set_lr, 10, 10, rec_list_lr, Item_popularity(train_set_lr))\n",
    "recall = Recall(train_set, test_set, 10, 10, rec_list)\n",
    "precision=Precision(train_set, test_set, 10, 10, rec_list)\n",
    "cover = Coverage(train_set, test_set, 10, 10, rec_list,All_item(train_set))\n",
    "popular = Popularity(train_set, test_set, 10, 10, rec_list, Item_popularity(train_set))\n",
    "\n",
    "print('lr result: Recall:{}; Precision:{}; Coverage:{}; Popularity:{}'.format(recall_lr,precision_lr,cover_lr,popular_lr))\n",
    "print('No result: recall:{}; precision:{}; Coverage:{}; Popularity:{}'.format(recall,precision,cover,popular))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
